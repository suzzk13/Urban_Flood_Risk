{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efafcec4",
   "metadata": {},
   "source": [
    "# Urban Flood Risk\n",
    "\n",
    "**Problem Statement:**  \n",
    "Urban flooding poses significant risks to infrastructure, public safety, and economic stability. This project focuses on identifying flood-prone areas within cities, analyzing the underlying causes, and providing actionable insights to support urban planning and disaster management efforts.\n",
    "\n",
    "**Description:**  \n",
    "This project utilizes a synthetic dataset cataloging micro-areas (“segments”) across global cities to assess urban pluvial (rainfall-driven) flood risk. Each record represents a spatial segment with geographic coordinates, hydrologic context, drainage infrastructure characteristics, rainfall sources and intensities, and qualitative risk labels. By integrating global elevation and land datasets, local/remote rainfall sources, and infrastructure proximity metrics, the project supports hotspot detection, risk scoring, model training, and operational monitoring for effective flood risk management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional required libraries\n",
    "%pip install seaborn scikit-learn\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "\n",
    "# Import all necessary libraries for comprehensive analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53abc564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  segment_id             city_name    admin_ward   latitude   longitude  \\\n",
      "0  SEG-00001    Colombo, Sri Lanka  Borough East   6.920633   79.912600   \n",
      "1  SEG-00002        Chennai, India        Ward D  13.076487   80.281774   \n",
      "2  SEG-00003      Ahmedabad, India     Sector 12  23.019473   72.638578   \n",
      "3  SEG-00004      Hong Kong, China     Sector 14  22.302602  114.078673   \n",
      "4  SEG-00005  Durban, South Africa      Sector 5 -29.887602   30.911008   \n",
      "\n",
      "  catchment_id  elevation_m            dem_source       land_use soil_group  \\\n",
      "0      CAT-136          NaN  Copernicus_EEA-10_v5  Institutional        NaN   \n",
      "1      CAT-049        -2.19  Copernicus_EEA-10_v5    Residential          D   \n",
      "2      CAT-023        30.88             SRTM_3arc     Industrial          B   \n",
      "3      CAT-168        24.28             SRTM_3arc    Residential          B   \n",
      "4      CAT-171        35.70             SRTM_3arc     Industrial          C   \n",
      "\n",
      "   drainage_density_km_per_km2  storm_drain_proximity_m storm_drain_type  \\\n",
      "0                         4.27                    160.5        CurbInlet   \n",
      "1                         7.54                      NaN      OpenChannel   \n",
      "2                        11.00                    152.5      OpenChannel   \n",
      "3                         7.32                     37.0          Manhole   \n",
      "4                         4.50                    292.4      OpenChannel   \n",
      "\n",
      "  rainfall_source  historical_rainfall_intensity_mm_hr  return_period_years  \\\n",
      "0            ERA5                                 39.4                   50   \n",
      "1            ERA5                                 56.8                   25   \n",
      "2             IMD                                 16.3                    5   \n",
      "3            ERA5                                 77.0                   10   \n",
      "4            ERA5                                 20.8                    5   \n",
      "\n",
      "                                  risk_labels  \n",
      "0                                     monitor  \n",
      "1  ponding_hotspot|low_lying|event_2025-05-02  \n",
      "2                                     monitor  \n",
      "3                                     monitor  \n",
      "4                                     monitor  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/intern_dataset/archive/urban_pluvial_flood_risk_dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b843f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"URBAN FLOOD RISK DATASET - EXPLORATORY DATA ANALYSIS\")\n",
    "# Load the dataset\n",
    "df=pd.read_csv(\"D:/intern_dataset/archive/urban_pluvial_flood_risk_dataset.csv\")\n",
    "\n",
    "print(f\"\\n1. DATASET OVERVIEW:\")\n",
    "print(f\"   • Dataset Shape: {df.shape}\")\n",
    "print(f\"   • Number of Rows: {df.shape[0]:,}\")\n",
    "print(f\"  Number of Columns: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n2. COLUMN INFORMATION:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\n3. FIRST 5 ROWS:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\n4. LAST 5 ROWS:\")\n",
    "print(df.tail())       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74920ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n MISSING VALUES ANALYSIS:\")\n",
    "\n",
    "# Calculate missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing_Count': missing_values.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")\n",
    "\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Percentage of missing data: {(df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n STATISTICS:\")\n",
    "\n",
    "\n",
    "# Numerical columns summary\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {list(numerical_cols)}\")\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "    print(df[numerical_cols].describe().round(2))\n",
    "\n",
    "# Categorical columns summary\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {list(categorical_cols)}\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"\\nCategorical Columns Summary:\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  • Unique values: {df[col].nunique()}\")\n",
    "        print(f\"  • Most frequent: {df[col].mode().iloc[0] if not df[col].mode().empty else 'N/A'}\")\n",
    "        if df[col].nunique() <= 10:  # Show value counts for columns with few unique values\n",
    "            print(f\"  • Value counts:\")\n",
    "            print(df[col].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5367126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='storm_drain_type', data=df)\n",
    "plt.title('storm drain type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "num_cols = [\"latitude\",\"longitude\",\"elevation_m\",\"return_period_years\"]\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(num_cols) / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, col in zip(axes, num_cols):\n",
    "    sns.histplot(df[col].dropna(), ax=ax, kde=True, bins=30)\n",
    "    ax.set_title(f\"{col} distribution\")\n",
    "\n",
    "# remove empty axes if any\n",
    "for ax in axes[len(num_cols):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter + trend\n",
    "sns.regplot(data=df, x=\"elevation_m\", y=\"historical_rainfall_intensity_mm_hr\", scatter_kws={\"alpha\":0.5})\n",
    "plt.title(\"Elevation vs Rainfall Intensity\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Joint distribution\n",
    "sns.jointplot(data=df, x=\"latitude\", y=\"elevation_m\", kind=\"hex\", height=5); plt.show()\n",
    "\n",
    "# Correlation (subset)\n",
    "cols = [\"latitude\",\"longitude\",\"elevation_m\",\"return_period_years\"]\n",
    "sns.heatmap(df[cols].corr(), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "sns.pairplot(df, vars=num_cols, hue='storm_drain_type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "le=LabelEncoder()\n",
    "categorical_cols=['city_name','admin_ward','catchment_id','land_use', 'soil_group','drainage_density_km_per_km2', 'storm_drain_proximity_m','storm_drain_type', 'rainfall_source','historical_rainfall_intensity_mm_hr', 'return_period_years']\n",
    "for col in categorical_cols:\n",
    "    df(cols)=le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46761c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_urban\"] = df[\"is_urban\"].str.strip().str.lower().map({\"true\": 1, \"false\": 0}).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target selection\n",
    "x=df.drop('storm_drain_type',axis=1)\n",
    "y=df['storm_drain_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc48451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d83528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale  num features\n",
    "scaler= StandardScaler()\n",
    "X_train[num_cols]=scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols]=scaler.fit_transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
